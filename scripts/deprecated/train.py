#!/usr/bin/env python3
"""
Train custom classifier on collected car noise data

Usage:
    python train.py
    python train.py --data-dir data/training --output data/models/car_classifier.pkl
"""

import sys
import argparse
import numpy as np
from pathlib import Path
from typing import List, Tuple
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import time

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

from models.mediapipe_classifier import MediaPipeAudioClassifier
from audio.capture import AudioFileLoader
from diagnosis.analyzer import PROBLEM_LABELS, LABEL_TO_NAME


def load_training_data(data_dir: Path, classifier: MediaPipeAudioClassifier) -> Tuple[np.ndarray, np.ndarray, List[str]]:
    """Load all training data and extract embeddings

    Args:
        data_dir: Directory containing subdirectories for each class
        classifier: MediaPipe classifier for embedding extraction

    Returns:
        X: Feature embeddings (n_samples, n_features)
        y: Labels (n_samples,)
        file_paths: List of file paths for reference
    """
    X_list = []
    y_list = []
    file_paths = []

    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘: {data_dir}")
    print("=" * 60)

    # Supported audio formats
    audio_extensions = ['*.wav', '*.mp3', '*.mp4', '*.m4a', '*.flac', '*.ogg']

    for label_name, label_id in PROBLEM_LABELS.items():
        class_dir = data_dir / label_name

        if not class_dir.exists():
            print(f"âš ï¸  í´ë” ì—†ìŒ: {class_dir}")
            continue

        # Find all audio files
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(class_dir.glob(ext))

        if not audio_files:
            print(f"âš ï¸  {label_name}: ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ")
            continue

        print(f"\nğŸ”Š {label_name} ({label_id}): {len(audio_files)}ê°œ íŒŒì¼")

        for i, audio_file in enumerate(audio_files, 1):
            try:
                # Load audio
                audio_data, sample_rate = AudioFileLoader.load_audio(str(audio_file))

                if len(audio_data) == 0:
                    print(f"  âš ï¸  [{i}/{len(audio_files)}] ë¹ˆ íŒŒì¼: {audio_file.name}")
                    continue

                # Extract embedding
                embedding = classifier.extract_embedding(audio_data, sample_rate)

                if embedding is None:
                    print(f"  âš ï¸  [{i}/{len(audio_files)}] ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {audio_file.name}")
                    continue

                X_list.append(embedding)
                y_list.append(label_id)
                file_paths.append(str(audio_file))

                print(f"  âœ… [{i}/{len(audio_files)}] {audio_file.name} (íŠ¹ì„±: {len(embedding)}ì°¨ì›)")

            except Exception as e:
                print(f"  âŒ [{i}/{len(audio_files)}] ì˜¤ë¥˜: {audio_file.name} - {e}")
                continue

    if not X_list:
        raise ValueError("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/training/ í´ë”ì— ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”.")

    X = np.array(X_list)
    y = np.array(y_list)

    print("\n" + "=" * 60)
    print(f"âœ… ì´ {len(X)}ê°œ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ")
    print(f"   íŠ¹ì„± ì°¨ì›: {X.shape[1]}")
    print(f"   í´ë˜ìŠ¤ ë¶„í¬:")
    for label_id in np.unique(y):
        count = np.sum(y == label_id)
        label_name = LABEL_TO_NAME.get(label_id, f"unknown_{label_id}")
        print(f"     - {label_name}: {count}ê°œ ({count/len(y)*100:.1f}%)")

    return X, y, file_paths


def train_classifier(X: np.ndarray, y: np.ndarray) -> RandomForestClassifier:
    """Train Random Forest classifier

    Args:
        X: Feature embeddings
        y: Labels

    Returns:
        Trained classifier
    """
    print("\nğŸ¯ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    print("=" * 60)

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print(f"í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")

    # Train Random Forest
    clf = RandomForestClassifier(
        n_estimators=100,
        max_depth=20,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1,
        verbose=1
    )

    print("\nRandom Forest í•™ìŠµ ì¤‘...")
    start_time = time.time()
    clf.fit(X_train, y_train)
    training_time = time.time() - start_time

    print(f"âœ… í•™ìŠµ ì™„ë£Œ ({training_time:.1f}ì´ˆ)")

    # Evaluate
    print("\nğŸ“Š ëª¨ë¸ í‰ê°€:")
    print("-" * 60)

    # Training accuracy
    train_pred = clf.predict(X_train)
    train_acc = accuracy_score(y_train, train_pred)
    print(f"í›ˆë ¨ ì •í™•ë„: {train_acc:.2%}")

    # Test accuracy
    test_pred = clf.predict(X_test)
    test_acc = accuracy_score(y_test, test_pred)
    print(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.2%}")

    # Cross-validation
    print("\n5-Fold Cross Validation ì¤‘...")
    cv_scores = cross_val_score(clf, X, y, cv=5, n_jobs=-1)
    print(f"CV í‰ê·  ì •í™•ë„: {cv_scores.mean():.2%} (+/- {cv_scores.std() * 2:.2%})")

    # Classification report
    print("\në¶„ë¥˜ ë³´ê³ ì„œ (í…ŒìŠ¤íŠ¸ ë°ì´í„°):")
    print("-" * 60)
    target_names = [LABEL_TO_NAME.get(i, f"class_{i}") for i in sorted(np.unique(y))]
    print(classification_report(y_test, test_pred, target_names=target_names, zero_division=0))

    # Confusion matrix
    print("í˜¼ë™ í–‰ë ¬:")
    print("-" * 60)
    cm = confusion_matrix(y_test, test_pred)
    print(cm)

    # Feature importance (top 10)
    print("\nì¤‘ìš” íŠ¹ì„± (Top 10):")
    print("-" * 60)
    feature_importance = clf.feature_importances_
    top_indices = np.argsort(feature_importance)[-10:][::-1]
    for rank, idx in enumerate(top_indices, 1):
        print(f"  {rank:2}. Feature {idx:3}: {feature_importance[idx]:.4f}")

    return clf


def main():
    parser = argparse.ArgumentParser(description="Train car noise classifier")
    parser.add_argument(
        '--data-dir',
        type=str,
        default='data/training',
        help='Directory containing training data (default: data/training)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='data/models/car_classifier.pkl',
        help='Output model path (default: data/models/car_classifier.pkl)'
    )
    parser.add_argument(
        '--yamnet-model',
        type=str,
        default='data/models/yamnet.tflite',
        help='YAMNet model path (default: data/models/yamnet.tflite)'
    )

    args = parser.parse_args()

    print("ğŸš— ìë™ì°¨ ì†ŒìŒ ë¶„ë¥˜ê¸° í•™ìŠµ")
    print("=" * 60)

    # Check paths
    data_dir = Path(args.data_dir)
    output_path = Path(args.output)
    yamnet_path = Path(args.yamnet_model)

    if not data_dir.exists():
        print(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
        print(f"ë‹¤ìŒ êµ¬ì¡°ë¡œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”:")
        print(f"  {data_dir}/")
        print(f"    â”œâ”€â”€ normal/")
        print(f"    â”œâ”€â”€ engine_problem/")
        print(f"    â”œâ”€â”€ brake_problem/")
        print(f"    â””â”€â”€ ...")
        return 1

    if not yamnet_path.exists():
        print(f"âŒ YAMNet ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {yamnet_path}")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
        print(f"curl -L 'https://storage.googleapis.com/mediapipe-models/audio_classifier/yamnet/float32/1/yamnet.tflite' -o {yamnet_path}")
        return 1

    # Create output directory
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # Initialize classifier
    print(f"\nğŸ¤– YAMNet ëª¨ë¸ ë¡œë”©: {yamnet_path}")
    classifier = MediaPipeAudioClassifier(
        model_path=str(yamnet_path),
        max_results=50,
        score_threshold=0.0
    )

    # Load data
    try:
        X, y, file_paths = load_training_data(data_dir, classifier)
    except ValueError as e:
        print(f"\nâŒ {e}")
        return 1

    # Check minimum samples
    if len(X) < 10:
        print(f"\nâŒ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ ({len(X)}ê°œ). ìµœì†Œ 10ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")
        return 1

    # Train model
    trained_model = train_classifier(X, y)

    # Save model
    print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘: {output_path}")
    with open(output_path, 'wb') as f:
        pickle.dump(trained_model, f)

    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
    print("\nì‚¬ìš© ë°©ë²•:")
    print("  python main.py")
    print("  â†’ ì €ì¥ëœ ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.")

    return 0


if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
