#!/usr/bin/env python3
"""
Extract Candidate Knocking Segments for Manual Review
YAMNetìœ¼ë¡œ 1ì°¨ í•„í„°ë§ â†’ ì‚¬ìš©ì ìˆ˜ë™ ê²€ìˆ˜
"""

import sys
import numpy as np
from pathlib import Path
import soundfile as sf

sys.path.append(str(Path(__file__).parent / "src"))

from models.mediapipe_classifier import MediaPipeAudioClassifier
from audio.capture import AudioFileLoader


def get_engine_knocking_score(classifications):
    """Get 'Engine knocking' score from YAMNet"""
    knocking_score = 0.0
    top_pred = ""

    for result in classifications:
        categories = result.get('categories', [])
        if categories:
            top_pred = categories[0]['category_name']

        for category in categories:
            category_name = category['category_name'].lower()
            score = category['score']

            if 'engine' in category_name and 'knock' in category_name:
                knocking_score = max(knocking_score, score)

    return knocking_score, top_pred


def extract_candidates(audio_path: Path,
                       classifier: MediaPipeAudioClassifier,
                       output_dir: Path,
                       window_size: float = 1.5,
                       hop_size: float = 0.75,
                       threshold: float = 0.2) -> int:
    """
    Extract candidate segments for manual review

    Args:
        threshold: YAMNet 'Engine knocking' ìµœì†Œ ì ìˆ˜ (ë‚®ê²Œ ì„¤ì •í•´ì„œ í›„ë³´ ë§ì´ ì¶”ì¶œ)
    """
    print(f"\nğŸ“‚ ì²˜ë¦¬ ì¤‘: {audio_path.name}")

    # Load audio
    try:
        audio_data, sample_rate = AudioFileLoader.load_audio(str(audio_path))
    except Exception as e:
        print(f"  âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return 0

    duration = len(audio_data) / sample_rate
    print(f"  â±ï¸  ê¸¸ì´: {duration:.1f}ì´ˆ")

    # Window parameters
    window_samples = int(window_size * sample_rate)
    hop_samples = int(hop_size * sample_rate)

    candidates_saved = 0
    base_name = audio_path.stem

    # Sliding window
    for i, start_sample in enumerate(range(0, len(audio_data) - window_samples, hop_samples)):
        end_sample = start_sample + window_samples
        segment = audio_data[start_sample:end_sample]

        # Skip if too quiet
        rms = np.sqrt(np.mean(segment ** 2))
        if rms < 0.01:
            continue

        # Classify with YAMNet
        try:
            classifications = classifier.classify_audio(segment, sample_rate)
            knocking_score, top_pred = get_engine_knocking_score(classifications)

            # Save candidates (ë‚®ì€ thresholdë¡œ í›„ë³´ ë§ì´ ìˆ˜ì§‘)
            if knocking_score >= threshold:
                # íŒŒì¼ëª…ì— ì‹œê°„, ì ìˆ˜, Top ë¶„ë¥˜ í¬í•¨
                start_time = start_sample / sample_rate
                output_name = (f"{base_name}_"
                              f"t{start_time:06.1f}s_"
                              f"score{int(knocking_score*100):02d}_"
                              f"{candidates_saved:03d}.wav")

                output_path = output_dir / output_name
                sf.write(str(output_path), segment, sample_rate)

                print(f"  âœ… [{candidates_saved:3d}] {start_time:6.1f}s | "
                      f"ë…¸í‚¹: {knocking_score:5.1%} | Top: {top_pred}")
                candidates_saved += 1

        except Exception as e:
            print(f"  âš ï¸  ë¶„ë¥˜ ì˜¤ë¥˜ at {start_sample/sample_rate:.1f}s: {e}")
            continue

    print(f"  ğŸ’¾ ì´ {candidates_saved}ê°œ í›„ë³´ ì¶”ì¶œ")
    return candidates_saved


def main():
    print("="*80)
    print("ğŸ” í›„ë³´ ë…¸í‚¹ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ (ìˆ˜ë™ ê²€ìˆ˜ìš©)")
    print("="*80)

    # Paths
    input_dir = Path("data/training/engine_knocking")
    output_dir = Path("data/training/manual_workflow/1_candidates")
    yamnet_model = Path("data/models/yamnet.tflite")

    # Create output directory
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"\nğŸ“ ì…ë ¥:  {input_dir}")
    print(f"ğŸ“ ì¶œë ¥:  {output_dir}")
    print("\nâš™ï¸  ì„¤ì •:")
    print("   - ìœˆë„ìš°: 1.5ì´ˆ")
    print("   - Threshold: 20% (ë‚®ê²Œ ì„¤ì • - í›„ë³´ ë§ì´ ìˆ˜ì§‘)")
    print("   - ëª©ì : 1ì°¨ í•„í„°ë§ í›„ ìˆ˜ë™ ê²€ìˆ˜")

    # Check paths
    if not input_dir.exists():
        print(f"\nâŒ ì…ë ¥ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        return

    if not yamnet_model.exists():
        print(f"\nâŒ YAMNet ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {yamnet_model}")
        return

    # Load YAMNet
    print(f"\nğŸ¤– YAMNet ë¡œë“œ ì¤‘...")
    classifier = MediaPipeAudioClassifier(
        model_path=str(yamnet_model),
        max_results=10,
        score_threshold=0.0
    )
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # Find audio files
    audio_files = sorted(input_dir.glob("*.wav"))
    audio_files.extend(sorted(input_dir.glob("*.mp3")))
    audio_files.extend(sorted(input_dir.glob("*.mp4")))

    if not audio_files:
        print(f"\nâŒ {input_dir}ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return

    print(f"\nğŸ“Š ì´ {len(audio_files)}ê°œ íŒŒì¼ ë°œê²¬")

    # Process each file
    total_candidates = 0
    for audio_file in audio_files:
        candidates = extract_candidates(
            audio_path=audio_file,
            classifier=classifier,
            output_dir=output_dir,
            window_size=1.5,
            hop_size=0.75,
            threshold=0.2  # 20% ì´ìƒì´ë©´ í›„ë³´ë¡œ ì¶”ì¶œ
        )
        total_candidates += candidates

    # Summary
    print("\n" + "="*80)
    print("âœ… 1ì°¨ ì¶”ì¶œ ì™„ë£Œ!")
    print("="*80)
    print(f"ğŸ“Š í†µê³„:")
    print(f"   - ì›ë³¸ íŒŒì¼: {len(audio_files)}ê°œ")
    print(f"   - ì¶”ì¶œëœ í›„ë³´: {total_candidates}ê°œ")
    print(f"   - ì €ì¥ ìœ„ì¹˜: {output_dir}")
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   python review_segments.py  # ìˆ˜ë™ ê²€ìˆ˜ ì‹œì‘")
    print("="*80)


if __name__ == "__main__":
    main()
