#!/usr/bin/env python3
"""
Car Noise Diagnosis System
ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì…ë ¥ì„ ë°›ì•„ ìë™ì°¨ ì†ŒìŒì„ ë¶„ì„í•˜ê³  ê³ ì¥ ì§„ë‹¨ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import sys
import time
import numpy as np
from pathlib import Path

# Add src to Python path
sys.path.append(str(Path(__file__).parent / "src"))

from audio.capture import AudioCapture, AudioFileLoader
from models.mediapipe_classifier import MediaPipeAudioClassifier, AudioPreprocessor
from diagnosis.analyzer import CarNoiseDiagnoser, CarPartStatus


class CarNoiseDiagnosisSystem:
    def __init__(self, debug_mode=False):
        self.audio_capture = AudioCapture()
        self.debug_mode = debug_mode
        
        # YAMNet ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        model_path = Path(__file__).parent / "data" / "models" / "yamnet.tflite"
        if not model_path.exists():
            print(f"âš ï¸  ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            print("YAMNet ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
            print("curl -L 'https://storage.googleapis.com/mediapipe-models/audio_classifier/yamnet/float32/1/yamnet.tflite' -o data/models/yamnet.tflite")
            
        self.classifier = MediaPipeAudioClassifier(
            model_path=str(model_path), 
            max_results=10, 
            score_threshold=0.0  # ëª¨ë“  ê²°ê³¼ ë³´ê¸°
        )
        self.preprocessor = AudioPreprocessor()
        self.diagnoser = CarNoiseDiagnoser()
        
    def analyze_audio_file(self, file_path: str) -> dict:
        """íŒŒì¼ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë¡œë“œí•˜ì—¬ ë¶„ì„"""
        print(f"ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì¤‘: {file_path}")
        
        # Load audio file
        audio_data, sample_rate = AudioFileLoader.load_audio(file_path)
        
        if len(audio_data) == 0:
            return {"error": "ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
        return self._analyze_audio_data(audio_data, sample_rate)
    
    def analyze_realtime_continuous(self) -> None:
        """ì—°ì† ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„"""
        print("ğŸ™ï¸  ì—°ì† ì‹¤ì‹œê°„ ë¶„ì„ ëª¨ë“œ")
        print("Ctrl+Cë¥¼ ëˆŒëŸ¬ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
        print("ë§ˆì´í¬ì— ì†Œë¦¬ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”...")
        print("-" * 50)
        
        try:
            self.audio_capture.start_recording()
            
            analysis_interval = 3.0  # 3ì´ˆë§ˆë‹¤ ë¶„ì„
            
            while True:
                try:
                    # 3ì´ˆ ë™ì•ˆì˜ ì˜¤ë””ì˜¤ ìˆ˜ì§‘
                    audio_buffer = self.audio_capture.get_audio_buffer(analysis_interval)
                    
                    if len(audio_buffer) == 0:
                        print("âš ï¸  ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê³„ì† ì‹œë„ ì¤‘...")
                        time.sleep(1)
                        continue
                    
                    # ì˜¤ë””ì˜¤ ì…ë ¥ ìƒíƒœ í‘œì‹œ
                    rms = np.sqrt(np.mean(audio_buffer**2))
                    max_val = np.max(np.abs(audio_buffer))
                    print(f"ğŸ™ï¸  ë§ˆì´í¬ ì…ë ¥: RMS={rms:.4f}, ìµœëŒ€ê°’={max_val:.4f}, ê¸¸ì´={len(audio_buffer)}")
                    
                    # ë¶„ì„ ìˆ˜í–‰
                    print(f"\nğŸ” [{time.strftime('%H:%M:%S')}] ë¶„ì„ ì¤‘...")
                    result = self._analyze_audio_data(audio_buffer, self.audio_capture.sample_rate)
                    
                    if result.get('success', False):
                        # ê°„ëµí•œ ê²°ê³¼ë§Œ í‘œì‹œ (ì—°ì† ëª¨ë“œìš©)
                        self._print_continuous_report(result)
                    else:
                        print(f"âŒ ë¶„ì„ ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    
                    print("-" * 50)
                    
                except KeyboardInterrupt:
                    break
                except Exception as e:
                    print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                    time.sleep(1)
                    continue
                    
        except KeyboardInterrupt:
            pass
        finally:
            self.audio_capture.stop_recording()
            print("\nğŸ›‘ ì—°ì† ë¶„ì„ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
    
    def analyze_realtime_single(self, duration: float = 5.0) -> dict:
        """ë‹¨ì¼ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ (ê¸°ì¡´ ë°©ì‹)"""
        print(f"ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ ì‹œì‘ ({duration}ì´ˆ)")
        print("ë§ˆì´í¬ì— ì†Œë¦¬ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”...")
        
        try:
            self.audio_capture.start_recording()
            audio_buffer = self.audio_capture.get_audio_buffer(duration)
            self.audio_capture.stop_recording()
            
            if len(audio_buffer) == 0:
                return {"error": "ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
                
            return self._analyze_audio_data(audio_buffer, self.audio_capture.sample_rate)
            
        except Exception as e:
            return {"error": f"ì˜¤ë””ì˜¤ ìº¡ì²˜ ì˜¤ë¥˜: {str(e)}"}
    
    def _analyze_audio_data(self, audio_data: np.ndarray, sample_rate: int) -> dict:
        """ì˜¤ë””ì˜¤ ë°ì´í„° ë¶„ì„"""
        try:
            # 1. ìŒì„± í™œë™ ê°ì§€
            print("ìŒí–¥ í™˜ê²½ ë¶„ì„ ì¤‘...")
            voice_analysis = self.preprocessor.detect_voice_activity(audio_data, sample_rate)
            
            # 2. ë°°ê²½ ì†ŒìŒ í•„í„°ë§ (ìŒì„±ì´ ê°ì§€ë˜ë©´)
            processed_audio = audio_data
            if voice_analysis['voice_detected']:
                print(f"ğŸ¤ í˜¼í•© ìŒí–¥ ê°ì§€ë¨ ({voice_analysis['audio_type']}) - í•„í„°ë§ ì ìš©")
                processed_audio = self.preprocessor.filter_background_noise(audio_data, sample_rate)
            else:
                print("ğŸ”§ ê¸°ê³„ìŒ ìœ„ì£¼ ê°ì§€ë¨")
            
            # 3. MediaPipeë¡œ ê¸°ë³¸ ë¶„ë¥˜ (ì›ë³¸ê³¼ í•„í„°ë§ëœ ë²„ì „ ëª¨ë‘)
            print("ğŸ¤– MediaPipe YAMNet ë¶„ë¥˜ ì¤‘...")
            mediapipe_results_original = self.classifier.classify_audio(audio_data, sample_rate)
            
            # YAMNet ì›ë³¸ ë¶„ë¥˜ ê²°ê³¼ ì¦‰ì‹œ í‘œì‹œ
            if mediapipe_results_original:
                top_10 = self.classifier.get_top_predictions(mediapipe_results_original, top_k=10)
                print("   ğŸ¤– YAMNet ì‹¤ì‹œê°„ ë¶„ë¥˜ ê²°ê³¼ (Top 10):")
                for i, pred in enumerate(top_10, 1):
                    print(f"     {i:2}. {pred['category_name']:<25} {pred['score']:.1%}")
                    
                # ì°¨ëŸ‰ ê´€ë ¨ë§Œ ë³„ë„ í‘œì‹œ
                vehicle_sounds = self.classifier.filter_vehicle_sounds(mediapipe_results_original)
                if vehicle_sounds:
                    print("   ğŸš— ì°¨ëŸ‰ ê´€ë ¨ ì†Œë¦¬:")
                    for sound in vehicle_sounds[:3]:
                        print(f"     - {sound['category_name']}: {sound['score']:.1%}")
                else:
                    print("   âŒ ì°¨ëŸ‰ ê´€ë ¨ ì†Œë¦¬ ê°ì§€ë˜ì§€ ì•ŠìŒ")
            
            # í•„í„°ë§ëœ ì˜¤ë””ì˜¤ë¡œë„ ë¶„ë¥˜ ì‹œë„
            if voice_analysis['voice_detected'] and len(processed_audio) > 0:
                mediapipe_results_filtered = self.classifier.classify_audio(processed_audio, sample_rate)
                # ë‘ ê²°ê³¼ ì¤‘ ì°¨ëŸ‰ ê´€ë ¨ ì†ŒìŒì´ ë” ì˜ ê°ì§€ëœ ê²ƒ ì„ íƒ
                vehicle_sounds_original = self.classifier.filter_vehicle_sounds(mediapipe_results_original)
                vehicle_sounds_filtered = self.classifier.filter_vehicle_sounds(mediapipe_results_filtered)
                
                if len(vehicle_sounds_filtered) > len(vehicle_sounds_original):
                    print("âœ… í•„í„°ë§ëœ ì˜¤ë””ì˜¤ì—ì„œ ë” ë‚˜ì€ ê²°ê³¼ ê°ì§€")
                    mediapipe_results = mediapipe_results_filtered
                    analysis_audio = processed_audio
                else:
                    mediapipe_results = mediapipe_results_original  
                    analysis_audio = audio_data
            else:
                mediapipe_results = mediapipe_results_original
                analysis_audio = audio_data
            
            # 4. ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ
            print("ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ ì¤‘...")
            audio_features = self.preprocessor.extract_features(analysis_audio, sample_rate)
            engine_patterns = self.preprocessor.detect_engine_patterns(analysis_audio, sample_rate)
            
            # íŠ¹ì„± ë³‘í•©
            audio_features.update(engine_patterns)
            audio_features.update(voice_analysis)  # ìŒì„± ë¶„ì„ ê²°ê³¼ë„ í¬í•¨
            
            # 5. ì§„ë‹¨ ìˆ˜í–‰
            print("ìë™ì°¨ ì†ŒìŒ ì§„ë‹¨ ì¤‘...")
            diagnosis = self.diagnoser.diagnose(audio_features, mediapipe_results)
            
            # 6. ê²°ê³¼ ì •ë¦¬
            result = {
                'timestamp': time.time(),
                'audio_info': {
                    'duration': len(audio_data) / sample_rate,
                    'sample_rate': sample_rate,
                    'rms_level': audio_features.get('rms', 0),
                    'voice_detected': voice_analysis['voice_detected'],
                    'audio_type': voice_analysis['audio_type']
                },
                'mediapipe_results': mediapipe_results,
                'audio_features': audio_features,
                'diagnosis': diagnosis,
                'voice_analysis': voice_analysis,
                'filtering_applied': voice_analysis['voice_detected'],
                'success': True
            }
            
            return result
            
        except Exception as e:
            return {
                'error': f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                'success': False
            }
    
    def print_diagnosis_report(self, result: dict):
        """ì§„ë‹¨ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
        if not result.get('success', False):
            print(f"âŒ ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            return
            
        print("\n" + "="*60)
        print("ğŸš— ìë™ì°¨ ì†ŒìŒ ì§„ë‹¨ ê²°ê³¼")
        print("="*60)
        
        diagnosis = result['diagnosis']
        audio_info = result['audio_info']
        
        # ê¸°ë³¸ ì •ë³´
        print(f"ğŸ“Š ë¶„ì„ ì •ë³´:")
        print(f"   - ë¶„ì„ ì‹œê°„: {audio_info['duration']:.1f}ì´ˆ")
        print(f"   - ìƒ˜í”Œë§ ë ˆì´íŠ¸: {audio_info['sample_rate']} Hz")
        print(f"   - ìŒëŸ‰ ë ˆë²¨: {audio_info['rms_level']:.3f}")
        print(f"   - ì§„ë‹¨ ì‹ ë¢°ë„: {diagnosis['confidence']:.1%}")
        
        # ìŒí–¥ í™˜ê²½ ì •ë³´
        if 'voice_detected' in audio_info:
            voice_status = "ğŸ¤ ê°ì§€ë¨" if audio_info['voice_detected'] else "âŒ ì—†ìŒ"
            print(f"   - ìŒì„±: {voice_status}")
            print(f"   - ìŒí–¥ íƒ€ì…: {audio_info['audio_type']}")
            if result.get('filtering_applied'):
                print(f"   - ğŸ”§ ë°°ê²½ ì†ŒìŒ í•„í„°ë§ ì ìš©ë¨")
        
        # ì „ì²´ ìƒíƒœ
        status = diagnosis['overall_status']
        status_emoji = {
            CarPartStatus.NORMAL: "âœ…",
            CarPartStatus.WARNING: "âš ï¸",
            CarPartStatus.CRITICAL: "ğŸš¨"
        }
        
        print(f"\nğŸ¯ ì „ì²´ ìƒíƒœ: {status_emoji.get(status, 'â“')} {status.value}")
        
        # YAMNet ì „ì²´ ë¶„ë¥˜ ê²°ê³¼ (ìƒìœ„ 10ê°œ)
        if result.get('mediapipe_results'):
            all_predictions = self.classifier.get_top_predictions(result['mediapipe_results'], top_k=10)
            if all_predictions:
                print(f"\nğŸ¤– YAMNet ë¶„ë¥˜ ê²°ê³¼ (ìƒìœ„ 10ê°œ):")
                for i, pred in enumerate(all_predictions, 1):
                    print(f"   {i:2}. {pred['category_name']:<30} ({pred['score']:.1%})")
        
        # ê°ì§€ëœ ì†Œë¦¬
        if diagnosis['detected_sounds']:
            print(f"\nğŸ”Š ì°¨ëŸ‰ ê´€ë ¨ ì†Œë¦¬ í•„í„°ë§ ê²°ê³¼:")
            for sound in diagnosis['detected_sounds'][:5]:  # Top 5
                print(f"   - {sound['part']}: {sound['sound_type']} ({sound['confidence']:.1%})")
        else:
            print(f"\nğŸ”Š ì°¨ëŸ‰ ê´€ë ¨ ì†Œë¦¬: ê°ì§€ë˜ì§€ ì•ŠìŒ")
        
        # ë°œê²¬ëœ ë¬¸ì œë“¤
        if diagnosis['issues']:
            print(f"\nğŸ” ë°œê²¬ëœ ë¬¸ì œë“¤:")
            for i, issue in enumerate(diagnosis['issues'], 1):
                status_emoji_local = "ğŸš¨" if issue['status'] == "ìœ„í—˜" else "âš ï¸"
                print(f"   {i}. {status_emoji_local} [{issue['part']}] {issue['description']}")
                print(f"      ì‹ ë¢°ë„: {issue['confidence']:.1%}")
        else:
            print(f"\nâœ… íŠ¹ë³„í•œ ë¬¸ì œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì¶”ì²œ ì‚¬í•­
        if diagnosis['recommendations']:
            print(f"\nğŸ’¡ ì¶”ì²œ ì‚¬í•­:")
            for i, rec in enumerate(diagnosis['recommendations'], 1):
                print(f"   {i}. {rec}")
        
        print("\n" + "="*60)
    
    def _print_continuous_report(self, result: dict):
        """ì—°ì† ëª¨ë“œìš© ê°„ëµí•œ ì§„ë‹¨ ê²°ê³¼ ì¶œë ¥"""
        if not result.get('success', False):
            print(f"âŒ ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            return
            
        diagnosis = result['diagnosis']
        audio_info = result['audio_info']
        
        # ìƒíƒœ ì´ëª¨ì§€
        status = diagnosis['overall_status']
        status_emoji = {
            CarPartStatus.NORMAL: "âœ…",
            CarPartStatus.WARNING: "âš ï¸",
            CarPartStatus.CRITICAL: "ğŸš¨"
        }
        
        # í•œ ì¤„ ìš”ì•½
        print(f"ìƒíƒœ: {status_emoji.get(status, 'â“')} {status.value} | "
              f"ì‹ ë¢°ë„: {diagnosis['confidence']:.0%} | "
              f"ìŒëŸ‰: {audio_info['rms_level']:.3f}")
        
        # YAMNet ë¶„ë¥˜ ê²°ê³¼ (í•­ìƒ í‘œì‹œ)
        if result.get('mediapipe_results'):
            top_5 = self.classifier.get_top_predictions(result['mediapipe_results'], top_k=5)
            if top_5:
                print("ğŸ¤– YAMNet Top 5:")
                for i, p in enumerate(top_5, 1):
                    print(f"  {i}. {p['category_name']:<20} {p['score']:.0%}")
            
            # ì°¨ëŸ‰ ê´€ë ¨ ì†Œë¦¬ë§Œ ë³„ë„
            vehicle_sounds = self.classifier.filter_vehicle_sounds(result['mediapipe_results'])
            if vehicle_sounds:
                print(f"ğŸš— ì°¨ëŸ‰ìŒ: {', '.join([f'{s[\"category_name\"]}({s[\"score\"]:.0%})' for s in vehicle_sounds[:3]])}")
        else:
            print("âŒ YAMNet ë¶„ë¥˜ ê²°ê³¼ ì—†ìŒ")
        
        # ë¬¸ì œ ë°œê²¬ ì‹œë§Œ ìƒì„¸ í‘œì‹œ
        if diagnosis['issues']:
            critical_issues = [i for i in diagnosis['issues'] if i['status'] == CarPartStatus.CRITICAL.value]
            warning_issues = [i for i in diagnosis['issues'] if i['status'] == CarPartStatus.WARNING.value]
            
            if critical_issues:
                print("ğŸš¨ ê¸´ê¸‰:")
                for issue in critical_issues[:2]:  # ìµœëŒ€ 2ê°œë§Œ
                    print(f"  - {issue['part']}: {issue['description'][:40]}...")
            elif warning_issues:
                print("âš ï¸  ì£¼ì˜:")
                for issue in warning_issues[:1]:  # ìµœëŒ€ 1ê°œë§Œ
                    print(f"  - {issue['part']}: {issue['description'][:40]}...")
        else:
            print("âœ… ì´ìƒ ì—†ìŒ")


def main():
    print("ğŸš— ìë™ì°¨ ì†ŒìŒ ì§„ë‹¨ ì‹œìŠ¤í…œ v1.0")
    print("MediaPipe YAMNet ê¸°ë°˜")
    print("-" * 40)
    
    # ë””ë²„ê·¸ ëª¨ë“œ ì„ íƒ
    try:
        debug_choice = input("ë””ë²„ê·¸ ëª¨ë“œ (YAMNet ë¶„ë¥˜ ìƒì„¸ ë³´ê¸°)? (y/N): ").lower().strip().replace('\r', '')
        debug_mode = debug_choice in ['y', 'yes']
    except (KeyboardInterrupt, EOFError):
        debug_mode = False
    
    system = CarNoiseDiagnosisSystem(debug_mode=debug_mode)
    
    while True:
        print("\nì„ íƒí•˜ì„¸ìš”:")
        print("1. ì—°ì† ì‹¤ì‹œê°„ ë¶„ì„ (Ctrl+Cë¡œ ì¤‘ë‹¨)")
        print("2. ë‹¨ë°œ ì‹¤ì‹œê°„ ë¶„ì„ (5ì´ˆ)")
        print("3. ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„")
        print("4. ì¢…ë£Œ")
        
        choice = input("\nì…ë ¥ (1-4): ").strip().replace('\r', '')
        
        if choice == '1':
            print("\n" + "-" * 40)
            system.analyze_realtime_continuous()
            
        elif choice == '2':
            print("\n" + "-" * 40)
            result = system.analyze_realtime_single(duration=5.0)
            system.print_diagnosis_report(result)
            
        elif choice == '3':
            file_path = input("ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip().replace('\r', '')
            if Path(file_path).exists():
                print("\n" + "-" * 40)
                result = system.analyze_audio_file(file_path)
                system.print_diagnosis_report(result)
            else:
                print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        elif choice == '4':
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\ní”„ë¡œê·¸ë¨ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("requirements.txtì˜ íŒ¨í‚¤ì§€ë“¤ì´ ëª¨ë‘ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")